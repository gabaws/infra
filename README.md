# Infraestrutura GCP - GKE com Anthos Service Mesh

Este projeto provisiona uma infraestrutura escal√°vel no Google Cloud Platform (GCP) utilizando Terraform, seguindo as melhores pr√°ticas. A infraestrutura inclui:

- **Projeto GCP** criado usando [terraform-google-project-factory](https://github.com/terraform-google-modules/terraform-google-project-factory)
- **VPC** com subnets privadas e configura√ß√£o de Cloud NAT
- **2 Clusters GKE** em zonas diferentes para alta disponibilidade
- **Anthos Service Mesh** configurado para comunica√ß√£o entre pods em clusters separados

## üèõÔ∏è Arquitetura do Ambiente

### Vis√£o Geral

- **Governan√ßa**: projeto GCP dedicado criado via Project Factory, com APIs essenciais habilitadas e servi√ßo de billing associado.
- **Rede**: VPC customizada com sub-redes privadas replicadas em m√∫ltiplas regi√µes, Cloud NAT para sa√≠da controlada e regras de firewall opinadas.
- **C√¥mputo Kubernetes**: dois clusters GKE privados distribu√≠dos entre `us-central1-a` e `us-east1-b`, com Workload Identity, Auto-scaling, Network Policy e Binary Authorization.
- **Malha de Servi√ßo**: Anthos Service Mesh interligando os clusters e registrando-os no GKE Hub para tr√°fego seguro entre workloads.
- **Observabilidade**: integra√ß√µes nativas com Logging, Monitoring e Prometheus gerenciado.

```mermaid
flowchart TD
    subgraph Projeto["Projeto GCP (Project Factory)"]
        direction TB
        VPC["VPC customizada<br/>Rotas regionais"]
        subgraph Subnets["Sub-redes privadas"]
            S1["Subnet us-central1"]
            S2["Subnet us-east1"]
        end
        VPC --> S1
        VPC --> S2
        NAT["Cloud NAT"]
        VPC --> NAT
    end

    subgraph Cluster1["Cluster GKE 1<br/>us-central1-a"]
        N1["N&oacute;s privados<br/>Workload Identity"]
    end

    subgraph Cluster2["Cluster GKE 2<br/>us-east1-b"]
        N2["N&oacute;s privados<br/>Workload Identity"]
    end

    ASM["Anthos Service Mesh<br/>(GKE Hub + mTLS)"]
    Observabilidade["Logging / Monitoring / Prometheus"]

    S1 --> Cluster1
    S2 --> Cluster2
    Cluster1 --> ASM
    Cluster2 --> ASM
    ASM --> Observabilidade
```

> A vers√£o edit√°vel deste diagrama est√° dispon√≠vel em `docs/architecture-diagram.mmd`.

### Componentes Principais

#### Projeto e Estado

- **Provisionamento**: cria√ß√£o do projeto com pol√≠ticas organizacionais herdadas e APIs ativadas automaticamente.
- **Backend do Terraform**: suporta remote state em bucket GCS dedicado, garantindo controle de concorr√™ncia via Terraform Cloud Storage.

#### Rede (VPC)

- **Network**: VPC customizada com roteamento regional.
- **Subnets**: sub-redes privadas com ranges secund√°rios para pods e servi√ßos.
- **Cloud NAT**: garante acesso controlado √† internet para n√≥s privados.
- **Firewall Rules**: opinadas para comunica√ß√£o interna, monitoramento e (opcionalmente) acesso administrativo.

#### Clusters GKE

- **Distribui√ß√£o**: dois clusters privados em zonas diferentes (HA regional).
- **Workload Identity**: integra√ß√£o com IAM para fornecer identidades gerenciadas.
- **Auto-scaling**: defini√ß√£o de limites de n√≥s por pool, com escalonamento autom√°tico habilitado.
- **Network Policy**: isolamento de tr√°fego L3/L4 entre pods.
- **Logging e Monitoring**: envio nativo para servi√ßos de observabilidade do GCP e suporte a Prometheus gerenciado.

#### Anthos Service Mesh

- **GKE Hub**: registros centralizados dos clusters.
- **Service Mesh**: configura√ß√£o autom√°tica do plano de controle com certificados mTLS rotacionados.
- **Multi-cluster**: roteamento seguro entre pods em clusters distintos com pol√≠ticas unificadas.
- **Plano de dados automatizado**: instala√ß√£o do Istio (charts oficiais) em cada cluster com revision `asm-managed`.
- **Gateway & GitOps**: provisionamento do Ingress Gateway e do ArgoCD via Helm, com op√ß√µes de customiza√ß√£o em `terraform.tfvars`.

#### Seguran√ßa Complementar

- **Binary Authorization**: pol√≠ticas para garantir que apenas imagens confi√°veis sejam executadas.
- **Service Accounts**: refor√ßo para workloads com contas dedicadas e escopos m√≠nimos.
- **Master Authorized Networks**: suporte para restringir o endpoint do plano de controle, incluindo acesso privado opcional.

### Diagrama de Componentes (Caixinhas)

```mermaid
flowchart LR
    classDef module fill:#f3f4ff,stroke:#4f46e5,stroke-width:1px,color:#111827;
    classDef infra fill:#ecfeff,stroke:#0e7490,stroke-width:1px,color:#0f172a;
    classDef service fill:#fff7ed,stroke:#c2410c,stroke-width:1px,color:#1f2937;
    classDef observ fill:#fef3c7,stroke:#d97706,stroke-width:1px,color:#78350f;

    A["Project Factory<br/>(M&oacute;dulo Terraform)"]:::module --> B["Projeto GCP<br/>Billing + APIs"]:::infra
    B --> C["VPC Custom<br/>Subnets privadas"]:::infra
    C --> D1["Cloud NAT"]:::infra
    C --> D2["Firewall Rules"]:::infra
    C --> E1["Cluster GKE 1<br/>us-central1-a"]:::service
    C --> E2["Cluster GKE 2<br/>us-east1-b"]:::service
    E1 --> F["Anthos Service Mesh<br/>Plano de controle"]:::service
    E2 --> F
    F --> G["Observabilidade<br/>Logging / Monitoring / Prometheus"]:::observ
```

> A vers√£o edit√°vel deste diagrama est√° dispon√≠vel em `docs/architecture-components.mmd`.

## üìã Pr√©-requisitos

### Software Necess√°rio

- [Terraform](https://www.terraform.io/downloads) >= 1.3
- [Google Cloud SDK](https://cloud.google.com/sdk/docs/install) >= 269.0.0
- [jq](https://stedolan.github.io/jq/download/) >= 1.6 (para scripts auxiliares)

### Permiss√µes Necess√°rias

Para executar este m√≥dulo, voc√™ precisa de uma Service Account com as seguintes permiss√µes:

- `roles/resourcemanager.folderViewer` na pasta onde o projeto ser√° criado
- `roles/resourcemanager.organizationViewer` na organiza√ß√£o
- `roles/resourcemanager.projectCreator` na organiza√ß√£o
- `roles/billing.user` na organiza√ß√£o
- `roles/storage.admin` no projeto bucket (se aplic√°vel)

### APIs Necess√°rias

As seguintes APIs ser√£o habilitadas automaticamente no projeto:

- Cloud Resource Manager API
- Cloud Billing API
- Identity and Access Management API
- Compute Engine API
- Kubernetes Engine API
- GKE Hub API
- Anthos Service Mesh API
- Service Networking API
- Logging API
- Monitoring API

## üöÄ In√≠cio R√°pido

### 0. Configurar Backend Remoto (Opcional mas Recomendado)

Antes de come√ßar, configure o bucket para armazenar o estado do Terraform:

```bash
cd bootstrap/
cp terraform.tfvars.example terraform.tfvars
# Edite terraform.tfvars com suas informa√ß√µes
terraform init
terraform apply
```

Depois, configure o backend em `versions.tf` (descomente as linhas do backend) e execute:
```bash
terraform init -migrate-state
```

üìñ **Leia mais**: [Documenta√ß√£o completa sobre Backend e Estado](docs/BACKEND_AND_STATE.md)

### 1. Configurar Credenciais do GCP

```bash
# Autenticar no GCP
gcloud auth application-default login

# Ou configurar via vari√°vel de ambiente
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/credentials.json"
```

### 2. Configurar Vari√°veis

Copie o arquivo de exemplo e ajuste conforme necess√°rio:

```bash
cp terraform.tfvars.example terraform.tfvars
```

Edite `terraform.tfvars` com suas informa√ß√µes:

```hcl
project_id             = "infra-474223"
region                 = "us-central1"
primary_cluster_name   = "master-engine"
secondary_cluster_name = "app-engine"
argocd_target_cluster  = "master-engine"
```

### 3. Inicializar Terraform

```bash
terraform init
```

### 4. Planejar e Aplicar

```bash
# Ver o plano de execu√ß√£o
terraform plan

# Aplicar as mudan√ßas
terraform apply
```

> üí° **Primeiro deploy?**  
> Recursos que dependem de acesso direto ao cluster Kubernetes (Istio/ASM, ArgoCD, gateways) s√≥ podem ser instalados depois que os clusters GKE estiverem dispon√≠veis.  
> Execute em duas etapas:
>
> ```bash
> # Cria rede, clusters e mesh
> terraform apply -var enable_cluster_addons=false
>
> # Depois instala os add-ons (Istio, ArgoCD, etc.)
> terraform apply -var enable_cluster_addons=true
> ```
>
> Em execu√ß√µes subsequentes, um √∫nico `terraform apply` j√° consegue detectar os clusters existentes e criar/atualizar os add-ons normalmente.

### Automa√ß√£o via GitHub Actions

O workflow `Terraform Deploy GKE` j√° implementa essa estrat√©gia em dois est√°gios:

- **`terraform-apply-bootstrap`** √© executado somente quando o estado remoto ainda n√£o possui os clusters GKE. Ele roda `terraform plan/apply` com `enable_cluster_addons=false` para criar toda a base (VPC, GKE e ASM) sem tentar acessar o Kubernetes.
- **`terraform-apply-addons`** depende do bootstrap, aguarda os clusters ficarem dispon√≠veis e ent√£o roda `terraform plan/apply` com `enable_cluster_addons=true`, aplicando Istio, gateways e ArgoCD.

O job de **plan** detecta automaticamente se os clusters j√° existem e ajusta a vari√°vel `enable_cluster_addons`, evitando planos inconsistentes. Assim, em qualquer push para `main` (ou execu√ß√£o manual `workflow_dispatch`), a pipeline provisiona a infraestrutura e depois instala os add-ons sem precisar de interven√ß√µes manuais ou execu√ß√µes repetidas.

## üìÅ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ main.tf                          # Configura√ß√£o principal do Terraform
‚îú‚îÄ‚îÄ variables.tf                     # Vari√°veis do m√≥dulo raiz
‚îú‚îÄ‚îÄ outputs.tf                      # Outputs do m√≥dulo raiz
‚îú‚îÄ‚îÄ terraform.tfvars.example        # Exemplo de vari√°veis
‚îú‚îÄ‚îÄ README.md                       # Este arquivo
‚îú‚îÄ‚îÄ .gitignore                      # Arquivos ignorados pelo Git
‚îî‚îÄ‚îÄ modules/
    ‚îú‚îÄ‚îÄ vpc/                        # M√≥dulo de VPC
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf
    ‚îú‚îÄ‚îÄ gke/                        # M√≥dulo de GKE
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf
    ‚îú‚îÄ‚îÄ cluster-addons/             # Add-ons (Istio, Gateway, ArgoCD)
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
    ‚îÇ   ‚îî‚îÄ‚îÄ variables.tf
    ‚îî‚îÄ‚îÄ anthos-service-mesh/        # M√≥dulo de Anthos Service Mesh
        ‚îú‚îÄ‚îÄ main.tf
        ‚îú‚îÄ‚îÄ variables.tf
        ‚îî‚îÄ‚îÄ outputs.tf
```

## üîß Configura√ß√£o Avan√ßada

### Personalizar Clusters GKE

Edite a vari√°vel `gke_clusters` em `terraform.tfvars`:

```hcl
gke_clusters = {
  master-engine = {
    region                = "us-central1"
    zone                  = "us-central1-a"
    initial_node_count    = 2
    min_node_count        = 1
    max_node_count        = 10
    machine_type          = "e2-standard-4"
    disk_size_gb          = 100
    enable_private_nodes  = true
    enable_private_endpoint = false
  }
  app-engine = {
    region                = "us-east1"
    zone                  = "us-east1-b"
    initial_node_count    = 2
    min_node_count        = 1
    max_node_count        = 10
    machine_type          = "e2-standard-4"
    disk_size_gb          = 100
    enable_private_nodes  = true
    enable_private_endpoint = false
  }
}
```

> ‚öôÔ∏è Use as vari√°veis `primary_cluster_name`, `secondary_cluster_name` e `argocd_target_cluster`
> para indicar qual cluster √© o ‚Äúmaster‚Äù (recebe o ArgoCD) e qual ficar√° respons√°vel
> apenas por workloads. Por padr√£o `master-engine` hospeda o ArgoCD e `app-engine`
> participa da mesma malha, mas sem ArgoCD.

### Configurar Master Authorized Networks

Para acessar o endpoint privado do cluster:

```hcl
master_authorized_networks = [
  {
    cidr_block   = "10.0.0.0/8"
    display_name = "Internal Network"
  }
]
```

### Personalizar Subnets

Ajuste as subnets e ranges secund√°rios:

```hcl
subnets = [
  {
    name          = "subnet-custom"
    ip_cidr_range = "10.0.10.0/24"
    region        = "us-west1"
    description   = "Custom subnet"
  }
]

secondary_ranges = {
  "subnet-custom" = [
    {
      range_name    = "pods"
      ip_cidr_range = "10.10.0.0/16"
    },
    {
      range_name    = "services"
      ip_cidr_range = "10.20.0.0/20"
    }
  ]
}
```

### Reutilizar uma VPC existente

Caso a rede j√° exista no projeto (por exemplo, ambientes compartilhados), defina `manage_network = false` em `terraform.tfvars`. O m√≥dulo deixar√° de criar a VPC e reutilizar√° a rede chamada em `network_name`, mantendo a cria√ß√£o das subnets e dos demais recursos associados.

### Automatiza√ß√£o do ASM Gateway e ArgoCD

- `istio_chart_version`, `asm_revision`, `istiod_values` e `istio_gateway_values` controlam a instala√ß√£o do Istio (base, istiod e ingress gateway) via Helm em todos os clusters.
- `install_gateway`, `gateway_namespace` e `gateway_labels` permitem habilitar/desabilitar o gateway e customizar namespace/labels.
- `install_argocd`, `argocd_chart_version`, `argocd_values` definem a instala√ß√£o do ArgoCD. Use `argocd_target_cluster` para apontar qual cluster recebe o Argo (por padr√£o, `master-engine`).
- `manage_istio_namespace` controla se o Terraform deve criar/atualizar o namespace `istio-system`. Defina como `false` quando o namespace j√° √© provisionado automaticamente pelo Anthos Service Mesh, evitando erros de ‚Äúresource already exists‚Äù nos pipelines.
- Para adicionar novos clusters √© necess√°rio criar provedores `kubernetes`/`helm` com aliases adicionais em `main.tf` e instanciar o m√≥dulo `cluster-addons` correspondente.

## üìä Outputs

Ap√≥s o deploy, voc√™ pode acessar os seguintes outputs:

```bash
# ID do projeto criado
terraform output project_id

# Informa√ß√µes dos clusters
terraform output gke_clusters

# Status do Service Mesh
terraform output anthos_service_mesh_status
```

## üîê Seguran√ßa

### Boas Pr√°ticas Implementadas

- ‚úÖ N√≥s privados do GKE (sem IPs p√∫blicos)
- ‚úÖ Network Policy habilitada
- ‚úÖ Workload Identity para autentica√ß√£o
- ‚úÖ Service Account padr√£o desabilitada
- ‚úÖ Logging e monitoring habilitados
- ‚úÖ Binary Authorization configurado

### Recomenda√ß√µes Adicionais

1. **Habilitar Private Endpoint**: Configure `enable_private_endpoint = true` para clusters cr√≠ticos
2. **Master Authorized Networks**: Restrinja o acesso ao endpoint do master
3. **Service Account Custom**: Use service accounts espec√≠ficas para cada workload
4. **Secrets Management**: Use Secret Manager ou external-secrets para credenciais
5. **Pod Security Standards**: Configure Pod Security Standards nos namespaces

## üß™ Testando a Comunica√ß√£o entre Clusters

Ap√≥s o deploy, voc√™ pode testar a comunica√ß√£o entre clusters usando o Service Mesh:

```bash
# Conectar ao cluster master (master-engine)
gcloud container clusters get-credentials master-engine --zone us-central1-a --project $(terraform output -raw project_id)

# Conectar ao cluster de aplica√ß√µes (app-engine)
gcloud container clusters get-credentials app-engine --zone us-east1-b --project $(terraform output -raw project_id)

# Verificar o Service Mesh
kubectl get servicemesh -A
```

## üßπ Limpeza

Para destruir toda a infraestrutura:

```bash
terraform destroy
```

**‚ö†Ô∏è Aten√ß√£o**: Isso ir√° deletar todos os recursos, incluindo o projeto GCP (se configurado).

## üìö Recursos Adicionais

- [Terraform Google Project Factory](https://github.com/terraform-google-modules/terraform-google-project-factory)
- [GKE Best Practices](https://cloud.google.com/kubernetes-engine/docs/best-practices)
- [Anthos Service Mesh Documentation](https://cloud.google.com/service-mesh/docs)
- [Terraform Google Provider](https://registry.terraform.io/providers/hashicorp/google/latest/docs)

## ü§ù Contribuindo

1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìù Licen√ßa

Este projeto est√° sob a licen√ßa Apache 2.0. Veja o arquivo `LICENSE` para mais detalhes.

## üÜò Troubleshooting

### Erro: "API not enabled"

Certifique-se de que todas as APIs necess√°rias est√£o habilitadas. O m√≥dulo project-factory deve habilit√°-las automaticamente.

### Erro: "Insufficient permissions"

Verifique se a Service Account tem todas as permiss√µes necess√°rias listadas na se√ß√£o de Pr√©-requisitos.

### Clusters n√£o conseguem se comunicar via Service Mesh

1. Verifique se o Anthos Service Mesh est√° habilitado: `gcloud container hub mesh describe`
2. Verifique os membros do mesh: `gcloud container hub memberships list`
3. Verifique os logs: `kubectl logs -n istio-system`

## üìß Suporte

Para quest√µes e suporte, abra uma issue no reposit√≥rio.
