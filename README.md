# Infraestrutura GCP - GKE com Anthos Service Mesh

Este projeto provisiona uma infraestrutura escalÃ¡vel no Google Cloud Platform (GCP) utilizando Terraform, seguindo as melhores prÃ¡ticas. A infraestrutura inclui:

- **Projeto GCP** criado usando [terraform-google-project-factory](https://github.com/terraform-google-modules/terraform-google-project-factory)
- **VPC** com subnets privadas e configuraÃ§Ã£o de Cloud NAT
- **2 Clusters GKE** em zonas diferentes para alta disponibilidade
- **Anthos Service Mesh** configurado para comunicaÃ§Ã£o entre pods em clusters separados

## ğŸ›ï¸ Arquitetura do Ambiente

### VisÃ£o Geral

- **GovernanÃ§a**: projeto GCP dedicado criado via Project Factory, com APIs essenciais habilitadas e serviÃ§o de billing associado.
- **Rede**: VPC customizada com sub-redes privadas replicadas em mÃºltiplas regiÃµes, Cloud NAT para saÃ­da controlada e regras de firewall opinadas.
- **CÃ´mputo Kubernetes**: dois clusters GKE privados distribuÃ­dos entre `us-central1-a` e `us-east1-b`, com Workload Identity, Auto-scaling, Network Policy e Binary Authorization.
- **Malha de ServiÃ§o**: Anthos Service Mesh interligando os clusters e registrando-os no GKE Hub para trÃ¡fego seguro entre workloads.
- **Observabilidade**: integraÃ§Ãµes nativas com Logging, Monitoring e Prometheus gerenciado.

```mermaid
flowchart TD
    subgraph Projeto["Projeto GCP (Project Factory)"]
        direction TB
        VPC[VPC customizada\nRotas regionais]
        subgraph Subnets["Sub-redes privadas"]
            S1[Subnet us-central1]
            S2[Subnet us-east1]
        end
        VPC --> S1
        VPC --> S2
        NAT[Cloud NAT]
        VPC --> NAT
    end

    subgraph Cluster1["Cluster GKE 1\nus-central1-a"]
        N1[NÃ³s privados\nWorkload Identity]
    end

    subgraph Cluster2["Cluster GKE 2\nus-east1-b"]
        N2[NÃ³s privados\nWorkload Identity]
    end

    ASM[Anthos Service Mesh\n(GKE Hub + mTLS)]
    Observabilidade[(Logging / Monitoring / Prometheus)]

    S1 --> Cluster1
    S2 --> Cluster2
    Cluster1 --> ASM
    Cluster2 --> ASM
    ASM --> Observabilidade
```

> A versÃ£o editÃ¡vel deste diagrama estÃ¡ disponÃ­vel em `docs/architecture-diagram.mmd`.

### Componentes Principais

#### Projeto e Estado

- **Provisionamento**: criaÃ§Ã£o do projeto com polÃ­ticas organizacionais herdadas e APIs ativadas automaticamente.
- **Backend do Terraform**: suporta remote state em bucket GCS dedicado, garantindo controle de concorrÃªncia via Terraform Cloud Storage.

#### Rede (VPC)

- **Network**: VPC customizada com roteamento regional.
- **Subnets**: sub-redes privadas com ranges secundÃ¡rios para pods e serviÃ§os.
- **Cloud NAT**: garante acesso controlado Ã  internet para nÃ³s privados.
- **Firewall Rules**: opinadas para comunicaÃ§Ã£o interna, monitoramento e (opcionalmente) acesso administrativo.

#### Clusters GKE

- **DistribuiÃ§Ã£o**: dois clusters privados em zonas diferentes (HA regional).
- **Workload Identity**: integraÃ§Ã£o com IAM para fornecer identidades gerenciadas.
- **Auto-scaling**: definiÃ§Ã£o de limites de nÃ³s por pool, com escalonamento automÃ¡tico habilitado.
- **Network Policy**: isolamento de trÃ¡fego L3/L4 entre pods.
- **Logging e Monitoring**: envio nativo para serviÃ§os de observabilidade do GCP e suporte a Prometheus gerenciado.

#### Anthos Service Mesh

- **GKE Hub**: registros centralizados dos clusters.
- **Service Mesh**: configuraÃ§Ã£o automÃ¡tica do plano de controle com certificados mTLS rotacionados.
- **Multi-cluster**: roteamento seguro entre pods em clusters distintos com polÃ­ticas unificadas.

#### SeguranÃ§a Complementar

- **Binary Authorization**: polÃ­ticas para garantir que apenas imagens confiÃ¡veis sejam executadas.
- **Service Accounts**: reforÃ§o para workloads com contas dedicadas e escopos mÃ­nimos.
- **Master Authorized Networks**: suporte para restringir o endpoint do plano de controle, incluindo acesso privado opcional.

## ğŸ“‹ PrÃ©-requisitos

### Software NecessÃ¡rio

- [Terraform](https://www.terraform.io/downloads) >= 1.3
- [Google Cloud SDK](https://cloud.google.com/sdk/docs/install) >= 269.0.0
- [jq](https://stedolan.github.io/jq/download/) >= 1.6 (para scripts auxiliares)

### PermissÃµes NecessÃ¡rias

Para executar este mÃ³dulo, vocÃª precisa de uma Service Account com as seguintes permissÃµes:

- `roles/resourcemanager.folderViewer` na pasta onde o projeto serÃ¡ criado
- `roles/resourcemanager.organizationViewer` na organizaÃ§Ã£o
- `roles/resourcemanager.projectCreator` na organizaÃ§Ã£o
- `roles/billing.user` na organizaÃ§Ã£o
- `roles/storage.admin` no projeto bucket (se aplicÃ¡vel)

### APIs NecessÃ¡rias

As seguintes APIs serÃ£o habilitadas automaticamente no projeto:

- Cloud Resource Manager API
- Cloud Billing API
- Identity and Access Management API
- Compute Engine API
- Kubernetes Engine API
- GKE Hub API
- Anthos Service Mesh API
- Service Networking API
- Logging API
- Monitoring API

## ğŸš€ InÃ­cio RÃ¡pido

### 0. Configurar Backend Remoto (Opcional mas Recomendado)

Antes de comeÃ§ar, configure o bucket para armazenar o estado do Terraform:

```bash
cd bootstrap/
cp terraform.tfvars.example terraform.tfvars
# Edite terraform.tfvars com suas informaÃ§Ãµes
terraform init
terraform apply
```

Depois, configure o backend em `versions.tf` (descomente as linhas do backend) e execute:
```bash
terraform init -migrate-state
```

ğŸ“– **Leia mais**: [DocumentaÃ§Ã£o completa sobre Backend e Estado](docs/BACKEND_AND_STATE.md)

### 1. Configurar Credenciais do GCP

```bash
# Autenticar no GCP
gcloud auth application-default login

# Ou configurar via variÃ¡vel de ambiente
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/credentials.json"
```

### 2. Configurar VariÃ¡veis

Copie o arquivo de exemplo e ajuste conforme necessÃ¡rio:

```bash
cp terraform.tfvars.example terraform.tfvars
```

Edite `terraform.tfvars` com suas informaÃ§Ãµes:

```hcl
project_name        = "meu-projeto-gke"
org_id              = "123456789012"
billing_account_id  = "01ABCD-2EFGH3-4IJKL5"
folder_id           = "987654321098"  # Opcional
```

### 3. Inicializar Terraform

```bash
terraform init
```

### 4. Planejar e Aplicar

```bash
# Ver o plano de execuÃ§Ã£o
terraform plan

# Aplicar as mudanÃ§as
terraform apply
```

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ main.tf                          # ConfiguraÃ§Ã£o principal do Terraform
â”œâ”€â”€ variables.tf                     # VariÃ¡veis do mÃ³dulo raiz
â”œâ”€â”€ outputs.tf                      # Outputs do mÃ³dulo raiz
â”œâ”€â”€ terraform.tfvars.example        # Exemplo de variÃ¡veis
â”œâ”€â”€ README.md                       # Este arquivo
â”œâ”€â”€ .gitignore                      # Arquivos ignorados pelo Git
â””â”€â”€ modules/
    â”œâ”€â”€ vpc/                        # MÃ³dulo de VPC
    â”‚   â”œâ”€â”€ main.tf
    â”‚   â”œâ”€â”€ variables.tf
    â”‚   â””â”€â”€ outputs.tf
    â”œâ”€â”€ gke/                        # MÃ³dulo de GKE
    â”‚   â”œâ”€â”€ main.tf
    â”‚   â”œâ”€â”€ variables.tf
    â”‚   â””â”€â”€ outputs.tf
    â””â”€â”€ anthos-service-mesh/        # MÃ³dulo de Anthos Service Mesh
        â”œâ”€â”€ main.tf
        â”œâ”€â”€ variables.tf
        â””â”€â”€ outputs.tf
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Personalizar Clusters GKE

Edite a variÃ¡vel `gke_clusters` em `terraform.tfvars`:

```hcl
gke_clusters = {
  cluster-1 = {
    region                = "us-central1"
    zone                  = "us-central1-a"
    initial_node_count    = 2
    min_node_count        = 1
    max_node_count        = 10
    machine_type          = "e2-standard-4"
    disk_size_gb          = 100
    enable_private_nodes  = true
    enable_private_endpoint = false
  }
  # ...
}
```

### Configurar Master Authorized Networks

Para acessar o endpoint privado do cluster:

```hcl
master_authorized_networks = [
  {
    cidr_block   = "10.0.0.0/8"
    display_name = "Internal Network"
  }
]
```

### Personalizar Subnets

Ajuste as subnets e ranges secundÃ¡rios:

```hcl
subnets = [
  {
    name          = "subnet-custom"
    ip_cidr_range = "10.0.10.0/24"
    region        = "us-west1"
    description   = "Custom subnet"
  }
]

secondary_ranges = {
  "subnet-custom" = [
    {
      range_name    = "pods"
      ip_cidr_range = "10.10.0.0/16"
    },
    {
      range_name    = "services"
      ip_cidr_range = "10.20.0.0/20"
    }
  ]
}
```

### Reutilizar uma VPC existente

Caso a rede jÃ¡ exista no projeto (por exemplo, ambientes compartilhados), defina `manage_network = false` em `terraform.tfvars`. O mÃ³dulo deixarÃ¡ de criar a VPC e reutilizarÃ¡ a rede chamada em `network_name`, mantendo a criaÃ§Ã£o das subnets e dos demais recursos associados.

## ğŸ“Š Outputs

ApÃ³s o deploy, vocÃª pode acessar os seguintes outputs:

```bash
# ID do projeto criado
terraform output project_id

# InformaÃ§Ãµes dos clusters
terraform output gke_clusters

# Status do Service Mesh
terraform output anthos_service_mesh_status
```

## ğŸ” SeguranÃ§a

### Boas PrÃ¡ticas Implementadas

- âœ… NÃ³s privados do GKE (sem IPs pÃºblicos)
- âœ… Network Policy habilitada
- âœ… Workload Identity para autenticaÃ§Ã£o
- âœ… Service Account padrÃ£o desabilitada
- âœ… Logging e monitoring habilitados
- âœ… Binary Authorization configurado

### RecomendaÃ§Ãµes Adicionais

1. **Habilitar Private Endpoint**: Configure `enable_private_endpoint = true` para clusters crÃ­ticos
2. **Master Authorized Networks**: Restrinja o acesso ao endpoint do master
3. **Service Account Custom**: Use service accounts especÃ­ficas para cada workload
4. **Secrets Management**: Use Secret Manager ou external-secrets para credenciais
5. **Pod Security Standards**: Configure Pod Security Standards nos namespaces

## ğŸ§ª Testando a ComunicaÃ§Ã£o entre Clusters

ApÃ³s o deploy, vocÃª pode testar a comunicaÃ§Ã£o entre clusters usando o Service Mesh:

```bash
# Conectar ao cluster 1
gcloud container clusters get-credentials cluster-1 --zone us-central1-a --project $(terraform output -raw project_id)

# Conectar ao cluster 2
gcloud container clusters get-credentials cluster-2 --zone us-east1-b --project $(terraform output -raw project_id)

# Verificar o Service Mesh
kubectl get servicemesh -A
```

## ğŸ§¹ Limpeza

Para destruir toda a infraestrutura:

```bash
terraform destroy
```

**âš ï¸ AtenÃ§Ã£o**: Isso irÃ¡ deletar todos os recursos, incluindo o projeto GCP (se configurado).

## ğŸ“š Recursos Adicionais

- [Terraform Google Project Factory](https://github.com/terraform-google-modules/terraform-google-project-factory)
- [GKE Best Practices](https://cloud.google.com/kubernetes-engine/docs/best-practices)
- [Anthos Service Mesh Documentation](https://cloud.google.com/service-mesh/docs)
- [Terraform Google Provider](https://registry.terraform.io/providers/hashicorp/google/latest/docs)

## ğŸ¤ Contribuindo

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a Apache 2.0. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ†˜ Troubleshooting

### Erro: "API not enabled"

Certifique-se de que todas as APIs necessÃ¡rias estÃ£o habilitadas. O mÃ³dulo project-factory deve habilitÃ¡-las automaticamente.

### Erro: "Insufficient permissions"

Verifique se a Service Account tem todas as permissÃµes necessÃ¡rias listadas na seÃ§Ã£o de PrÃ©-requisitos.

### Clusters nÃ£o conseguem se comunicar via Service Mesh

1. Verifique se o Anthos Service Mesh estÃ¡ habilitado: `gcloud container hub mesh describe`
2. Verifique os membros do mesh: `gcloud container hub memberships list`
3. Verifique os logs: `kubectl logs -n istio-system`

## ğŸ“§ Suporte

Para questÃµes e suporte, abra uma issue no repositÃ³rio.
