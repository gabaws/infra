# Infraestrutura GCP - GKE com Anthos Service Mesh

Este reposit√≥rio cont√©m a infraestrutura como c√≥digo (IaC) para provisionar uma infraestrutura escal√°vel no Google Cloud Platform (GCP) com:

- **VPC** com subnets em m√∫ltiplas regi√µes
- **2 Clusters GKE** (master-engine e app-engine)
- **Anthos Service Mesh (ASM)** para comunica√ß√£o entre clusters
- **Cloud DNS** para gerenciamento de dom√≠nio
- **Certificate Manager** para certificados SSL/TLS wildcard

## üìã Pr√©-requisitos

- Terraform >= 1.3
- Conta GCP com projeto existente (`infra-474223`)
- Service Account configurado com Workload Identity para GitHub Actions
- Acesso ao projeto GCP para autentica√ß√£o local

## üöÄ In√≠cio R√°pido

### 1. Configura√ß√£o Local

```bash
# Autenticar no GCP
gcloud auth application-default login

# Inicializar Terraform
terraform init

# Revisar o plano
terraform plan

# Aplicar a infraestrutura
terraform apply
```

### 2. Configura√ß√£o do DNS

Ap√≥s o provisionamento, obtenha os nameservers:

```bash
terraform output dns_nameservers
```

Configure esses nameservers no seu provedor de dom√≠nio (GoDaddy, etc.).

## üì¶ O que √© Provisionado

### Infraestrutura Base
- **VPC**: Rede privada com subnets em `us-central1` e `us-east1`
- **GKE Clusters**: 
  - `master-engine` (us-central1-a)
  - `app-engine` (us-east1-b)
- **Anthos Service Mesh (ASM)**: Malha de servi√ßos gerenciada para comunica√ß√£o entre clusters
- **Cloud DNS**: Zona p√∫blica para `cloudab.online`
- **Certificate Manager**: Certificado wildcard `*.cloudab.online`

### O que √© Provisionado (Fleet e ASM)
- **GKE Hub Fleet**: Os clusters s√£o automaticamente registrados no Fleet
- **Anthos Service Mesh (ASM)**: Habilitado automaticamente em todos os clusters com gerenciamento autom√°tico
- Os clusters compartilham a mesma malha de servi√ßos (mesh) para comunica√ß√£o segura entre clusters


## üîß Vari√°veis Principais

Consulte `terraform.tfvars.example` para ver todas as vari√°veis dispon√≠veis.

Principais vari√°veis:
- `project_id`: ID do projeto GCP (padr√£o: `infra-474223`)
- `domain_name`: Dom√≠nio gerenciado no Cloud DNS (padr√£o: `cloudab.online`)
- `gke_clusters`: Configura√ß√£o dos clusters GKE

## üîÑ Pipeline CI/CD

O Terraform pode ser executado via pipeline CI/CD sem necessidade de `gcloud` CLI instalado, pois:
- Todos os recursos s√£o gerenciados via providers do Terraform (google, google-beta)
- N√£o h√° depend√™ncia de comandos locais (`kubectl`, `helm`, `gcloud`) durante o `terraform apply`

**Nota**: Se voc√™ configurar uma pipeline, certifique-se de que:
- As credenciais do GCP estejam configuradas (via Service Account)
- O provider do Terraform tenha as permiss√µes necess√°rias

## üìù Outputs Importantes

```bash
# Nameservers do DNS
terraform output dns_nameservers

# Informa√ß√µes dos clusters
terraform output gke_clusters

# Status do ASM
terraform output anthos_service_mesh_status

# Certificate Map ID
terraform output certificate_map_id
```

## üóëÔ∏è Destruir Infraestrutura

```bash
terraform destroy
```

Ou via GitHub Actions: `workflow_dispatch` com `operation: destroy`

## ‚ö†Ô∏è Troubleshooting

### Erro: "Already exists" ao recriar clusters GKE

**Problema**: Ap√≥s destruir os clusters GKE, ao tentar recri√°-los imediatamente, voc√™ pode receber o erro:
```
Error: googleapi: Error 409: Already exists: projects/.../clusters/...
```

**Causa**: O GCP precisa de tempo (geralmente 5-15 minutos) para limpar completamente os recursos do cluster ap√≥s a exclus√£o. Durante esse per√≠odo, o cluster ainda existe no sistema do GCP, mesmo que apare√ßa como "deletado" no console.

**Solu√ß√µes**:

1. **Aguardar a limpeza completa** (Recomendado):
   ```bash
   # Verificar se os clusters foram completamente removidos
   gcloud container clusters list --project=infra-474223
   
   # Aguardar at√© que a lista esteja vazia (pode levar 5-15 minutos)
   # Depois, executar novamente:
   terraform apply
   ```

2. **Verificar o estado do Terraform**:
   ```bash
   # Verificar se h√° recursos √≥rf√£os no estado
   terraform state list
   
   # Se necess√°rio, remover manualmente do estado
   terraform state rm module.gke_clusters[0].google_container_cluster.clusters["master-engine"]
   terraform state rm module.gke_clusters[0].google_container_cluster.clusters["app-engine"]
   ```

3. **For√ßar remo√ß√£o manual** (se o cluster estiver travado):
   ```bash
   # Remover o cluster manualmente via gcloud
   gcloud container clusters delete master-engine --zone=us-central1-a --project=infra-474223 --quiet
   gcloud container clusters delete app-engine --zone=us-east1-b --project=infra-474223 --quiet
   
   # Aguardar a remo√ß√£o completa e ent√£o executar:
   terraform apply
   ```

4. **Usar nomes diferentes temporariamente**:
   Se precisar recriar imediatamente, altere temporariamente os nomes dos clusters em `terraform.tfvars`:
   ```hcl
   gke_clusters = {
     master-engine-v2 = { ... }
     app-engine-v2 = { ... }
   }
   ```

**Preven√ß√£o**: Os timeouts foram configurados no m√≥dulo GKE para garantir que a destrui√ß√£o seja completa. Se o problema persistir, aguarde pelo menos 10 minutos ap√≥s a destrui√ß√£o antes de tentar recriar.

## üîó Anthos Service Mesh (ASM) / Cloud Service Mesh

O projeto provisiona automaticamente:

1. **Registro no Fleet**: Ambos os clusters s√£o registrados automaticamente no GKE Hub Fleet
2. **Anthos Service Mesh (Cloud Service Mesh)**: A feature do ASM √© habilitada no Fleet e configurada com gerenciamento autom√°tico usando o provider `google-beta`
3. **Feature Membership**: Cada cluster √© registrado na feature do ASM para compartilhar a mesma malha de servi√ßos

### Como Funciona

- Os clusters `master-engine` e `app-engine` fazem parte da mesma **malha de servi√ßos (mesh)**
- Comunica√ß√£o entre clusters √© feita atrav√©s do ASM com mTLS autom√°tico
- O gerenciamento √© autom√°tico (`MANAGEMENT_AUTOMATIC`), ent√£o o ASM √© instalado e mantido automaticamente pelo Google Cloud
- **Descoberta autom√°tica de servi√ßos**: Com clusters na mesma VPC, Fleet e ASM com gerenciamento autom√°tico, a descoberta de servi√ßos entre clusters funciona automaticamente

### Configura√ß√£o T√©cnica

O m√≥dulo `anthos-service-mesh` usa explicitamente o provider `google-beta` para os recursos:
- `google_gke_hub_feature` (feature do Service Mesh)
- `google_gke_hub_feature_membership` (membership dos clusters)

Isso garante que o Cloud Service Mesh seja habilitado corretamente e apare√ßa como configurado no Feature Manager do GCP.

### Verificar Status do ASM

```bash
# Verificar status da feature do ASM
gcloud container hub features describe servicemesh --project=infra-474223 --location=global

# Verificar memberships dos clusters
terraform output anthos_service_mesh_status

# Listar clusters no Fleet
gcloud container fleet memberships list --project=infra-474223

# Verificar feature memberships (deve mostrar MANAGEMENT_AUTOMATIC)
gcloud container hub memberships describe master-engine-membership --project=infra-474223 --location=global
gcloud container hub memberships describe app-engine-membership --project=infra-474223 --location=global
```

### Troubleshooting: Feature n√£o aparece como configurado

Se o Cloud Service Mesh n√£o aparecer como habilitado no Feature Manager:

1. **Verificar se o provider google-beta est√° configurado**:
   ```bash
   terraform providers
   # Deve mostrar google-beta
   ```

2. **Verificar se os recursos foram criados com o provider correto**:
   ```bash
   terraform state list | grep anthos_service_mesh
   # Deve mostrar recursos com provider google-beta
   ```

3. **Reaplicar o m√≥dulo se necess√°rio**:
   ```bash
   terraform apply -target=module.anthos_service_mesh
   ```

4. **Aguardar alguns minutos**: Ap√≥s aplicar, pode levar 5-10 minutos para o Feature Manager atualizar o status

### Notas Importantes

- ‚úÖ O ASM √© provisionado automaticamente via Terraform usando o provider `google-beta`
- ‚úÖ Ambos os clusters compartilham a mesma malha de servi√ßos
- ‚úÖ mTLS √© habilitado automaticamente para comunica√ß√£o segura entre clusters
- ‚úÖ **Descoberta autom√°tica de servi√ßos**: Com clusters na mesma VPC, Fleet e ASM com gerenciamento autom√°tico, a descoberta de servi√ßos entre clusters funciona automaticamente
- ‚ö†Ô∏è **Provider google-beta obrigat√≥rio**: Os recursos do Service Mesh devem usar o provider `google-beta` para funcionar corretamente
- ‚ÑπÔ∏è Exemplos de uso e testes est√£o dispon√≠veis em `app-demo/` (n√£o fazem parte do provisionamento)

## üß™ Testes e Valida√ß√£o da Arquitetura

Ap√≥s o provisionamento da infraestrutura, voc√™ pode validar que tudo est√° funcionando corretamente usando os exemplos e scripts de teste dispon√≠veis em `app-demo/`.

### Arquitetura de Testes

A estrutura de testes demonstra a comunica√ß√£o multi-cluster usando o **Cloud Service Mesh** com descoberta autom√°tica:

```
app-demo/
‚îú‚îÄ‚îÄ README.md                    # Documenta√ß√£o completa dos testes
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh                # Deploy automatizado das aplica√ß√µes de teste
‚îÇ   ‚îú‚îÄ‚îÄ test-communication.sh    # Teste de comunica√ß√£o entre clusters
‚îÇ   ‚îî‚îÄ‚îÄ check-pods.sh            # Verifica√ß√£o de status dos pods
‚îú‚îÄ‚îÄ app-engine/                  # Aplica√ß√£o de teste no cluster app-engine
‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ service.yaml
‚îÇ   ‚îî‚îÄ‚îÄ kustomization.yaml
‚îî‚îÄ‚îÄ master-engine/               # Aplica√ß√£o de teste no cluster master-engine
    ‚îú‚îÄ‚îÄ namespace.yaml
    ‚îú‚îÄ‚îÄ deployment.yaml
    ‚îú‚îÄ‚îÄ service.yaml
    ‚îî‚îÄ‚îÄ kustomization.yaml
```

### Fluxo de Testes Recomendado

#### 1. Verificar Infraestrutura Provisionada

```bash
# Verificar clusters criados
gcloud container clusters list --project=infra-474223

# Verificar status do ASM
gcloud container hub features describe servicemesh --project=infra-474223 --location=global

# Verificar clusters no Fleet
gcloud container fleet memberships list --project=infra-474223

# Verificar que os clusters est√£o na mesma VPC
gcloud container clusters describe master-engine --location=us-central1-a --project=infra-474223 --format="value(network)"
gcloud container clusters describe app-engine --location=us-east1-b --project=infra-474223 --format="value(network)"
```

#### 2. Conectar aos Clusters

```bash
# Conectar ao cluster master-engine
gcloud container clusters get-credentials master-engine \
  --location=us-central1-a \
  --project=infra-474223

# Conectar ao cluster app-engine
gcloud container clusters get-credentials app-engine \
  --location=us-east1-b \
  --project=infra-474223
```

#### 3. Deploy das Aplica√ß√µes de Teste

```bash
cd app-demo

# Deploy automatizado (recomendado)
./scripts/deploy.sh

# Ou deploy manual
cd app-engine
kubectl apply -k . --context=gke_infra-474223_us-east1-b_app-engine

cd ../master-engine
kubectl apply -k . --context=gke_infra-474223_us-central1-a_master-engine
```

#### 4. Validar Comunica√ß√£o Multi-cluster

```bash
# Teste automatizado de comunica√ß√£o
./scripts/test-communication.sh

# Ou teste manual
# De app-engine para master-engine
kubectl run test-pod --image=curlimages/curl:latest --rm -it --restart=Never -n mcs-demo \
  --context=gke_infra-474223_us-east1-b_app-engine \
  --overrides='{"metadata":{"annotations":{"sidecar.istio.io/inject":"true"}}}' \
  -- curl http://hello-master-engine.mcs-demo.svc.cluster.local

# De master-engine para app-engine
kubectl run test-pod --image=curlimages/curl:latest --rm -it --restart=Never -n mcs-demo \
  --context=gke_infra-474223_us-central1-a_master-engine \
  --overrides='{"metadata":{"annotations":{"sidecar.istio.io/inject":"true"}}}' \
  -- curl http://hello-app-engine.mcs-demo.svc.cluster.local
```

### O que os Testes Validam

1. ‚úÖ **Descoberta Autom√°tica de Servi√ßos**: Servi√ßos em um cluster s√£o automaticamente descobertos por pods em outro cluster
2. ‚úÖ **Comunica√ß√£o Cross-cluster**: Pods podem se comunicar usando DNS padr√£o do Kubernetes (`svc.cluster.local`)
3. ‚úÖ **Inje√ß√£o Autom√°tica do Sidecar**: O Istio sidecar (`istio-proxy`) √© injetado automaticamente nos pods
4. ‚úÖ **mTLS Autom√°tico**: Comunica√ß√£o entre clusters √© criptografada automaticamente via mTLS
5. ‚úÖ **Roteamento Transparente**: O Cloud Service Mesh roteia automaticamente o tr√°fego para o cluster correto

### Caracter√≠sticas da Arquitetura de Testes

- **Simplicidade**: Apenas Deployment e Service Kubernetes padr√£o (sem ServiceEntry, ServiceExport ou VirtualService)
- **Descoberta Autom√°tica**: O Cloud Service Mesh gerencia tudo automaticamente
- **DNS Padr√£o**: Usa o DNS padr√£o do Kubernetes (`<service>.<namespace>.svc.cluster.local`)
- **Multi-cluster Transparente**: Aplica√ß√µes n√£o precisam saber em qual cluster est√£o rodando

### Documenta√ß√£o Detalhada

Para mais detalhes sobre os testes, consulte: **[app-demo/README.md](./app-demo/README.md)**

## üåê Multi-cluster Ingress

O **Multi-cluster Ingress** permite expor servi√ßos de m√∫ltiplos clusters GKE atrav√©s de um √∫nico ponto de entrada com balanceamento de carga global.

**‚ö†Ô∏è Importante**: O Multi-cluster Ingress **n√£o √© suportado pelo Terraform** e deve ser habilitado manualmente via `gcloud` ap√≥s o provisionamento da infraestrutura.

### Documenta√ß√£o

Para instru√ß√µes detalhadas sobre como habilitar o Multi-cluster Ingress, consulte: **[docs/MULTICLUSTER_INGRESS.md](./docs/MULTICLUSTER_INGRESS.md)**

### Notas Importantes

- ‚ö†Ô∏è O Multi-cluster Ingress **n√£o √© suportado pelo Terraform** e deve ser habilitado manualmente
- Requer um **config cluster** que gerencia a configura√ß√£o do ingress
- Todos os clusters devem estar registrados no mesmo **GKE Hub Fleet**
- Ap√≥s habilitar, pode levar alguns minutos para a propaga√ß√£o completa

