# Teste de Comunica√ß√£o Cross-Cluster no Cloud Service Mesh do GCP

## üìã Cen√°rio Testado

Este projeto testa a comunica√ß√£o entre pods em clusters GKE diferentes atrav√©s do **Cloud Service Mesh (ASM - Anthos Service Mesh)** gerenciado pelo Google.

### Infraestrutura Atual

- **2 Clusters GKE** em regi√µes diferentes
- **Mesmo Fleet** do GCP
- **VPC Compartilhada** configurada
- **Cloud Service Mesh (ASM)** habilitado e gerenciado pelo Google
- **Multi-cluster Service Mesh**: ‚ùå **N√ÉO HABILITADO**

### Clusters

1. **Cluster A**: `gke-dev-dis-app-engine`
   - Contexto: `gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine`
   - Namespace: `dev-dis-test`
   - Aplica√ß√£o: `dev-dis-test` (servidor HTTP na porta 80)

2. **Cluster B**: `gke-dev-get-app-engine`
   - Contexto: `gke_prj-dev-get-app-gke-cple_southamerica-east1_gke-dev-get-app-engine`
   - Namespace: `dev-get-test`
   - Aplica√ß√£o: `dev-get-test` (servidor HTTP na porta 5678, exposto na porta 80 do Service)

## üèóÔ∏è Arquitetura

### Cen√°rio Atual (Multi-cluster Mesh N√ÉO Habilitado)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Fleet do GCP                              ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Cluster A           ‚îÇ      ‚îÇ  Cluster B           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  (dev-dis-app)       ‚îÇ      ‚îÇ  (dev-get-app)       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                      ‚îÇ      ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Pod            ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ Pod            ‚îÇ  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ dev-dis-test   ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ dev-get-test   ‚îÇ  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ + istio-proxy   ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ + istio-proxy   ‚îÇ  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ             ‚îÇ      ‚îÇ         ‚îÇ             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Service     ‚îÇ      ‚îÇ      ‚îÇ  ‚îÇ Service     ‚îÇ      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ dev-dis-test ‚îÇ      ‚îÇ      ‚îÇ  ‚îÇ dev-get-test ‚îÇ      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                       ‚îÇ      ‚îÇ                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ServiceEntry   ‚îÇ   ‚îÇ      ‚îÇ  ‚îÇ ServiceEntry   ‚îÇ   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (dev-get)      ‚îÇ   ‚îÇ      ‚îÇ  ‚îÇ (dev-dis)      ‚îÇ   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ         ‚îÇ                              ‚îÇ                        ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                    ‚îÇ                                            ‚îÇ
‚îÇ         ‚ùå DNS n√£o resolve cross-cluster                        ‚îÇ
‚îÇ         ‚ö†Ô∏è  ServiceEntry com IP est√°tico necess√°rio             ‚îÇ
‚îÇ         ‚ö†Ô∏è  Sem descoberta autom√°tica de servi√ßos               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Cen√°rio Ideal (Multi-cluster Service Mesh Habilitado)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Fleet do GCP                              ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ     Istio Control Plane Multi-Cluster               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     (Descoberta autom√°tica de servi√ßos)              ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                    ‚îÇ                    ‚îÇ                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Cluster A              ‚îÇ  ‚îÇ  Cluster B             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  (dev-dis-app)          ‚îÇ  ‚îÇ  (dev-get-app)         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                         ‚îÇ  ‚îÇ                        ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Pod            ‚îÇ    ‚îÇ  ‚îÇ  ‚îÇ Pod            ‚îÇ    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ dev-dis-test   ‚îÇ    ‚îÇ  ‚îÇ  ‚îÇ dev-get-test   ‚îÇ    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ + istio-proxy   ‚îÇ    ‚îÇ  ‚îÇ  ‚îÇ + istio-proxy   ‚îÇ    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ               ‚îÇ  ‚îÇ         ‚îÇ               ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Service     ‚îÇ       ‚îÇ  ‚îÇ  ‚îÇ Service     ‚îÇ       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ dev-dis-test ‚îÇ       ‚îÇ  ‚îÇ  ‚îÇ dev-get-test ‚îÇ       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ         ‚îÇ                              ‚îÇ                      ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ
‚îÇ                    ‚îÇ                                          ‚îÇ
‚îÇ         ‚úÖ DNS resolve via Istio Control Plane                ‚îÇ
‚îÇ         ‚úÖ Descoberta autom√°tica de servi√ßos                  ‚îÇ
‚îÇ         ‚úÖ ServiceEntry n√£o necess√°rio                        ‚îÇ
‚îÇ         ‚úÖ Load balancing autom√°tico                          ‚îÇ
‚îÇ         ‚úÖ Observabilidade unificada                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Estrutura do Projeto

```
teste-mesh/
‚îú‚îÄ‚îÄ README.md                          # Esta documenta√ß√£o
‚îú‚îÄ‚îÄ gke-dev-dis-app-engine/           # Manifestos do Cluster A
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml               # Aplica√ß√£o principal (netshoot com servidor HTTP + ferramentas)
‚îÇ   ‚îú‚îÄ‚îÄ service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml
‚îÇ   ‚îú‚îÄ‚îÄ gateway.yaml
‚îÇ   ‚îú‚îÄ‚îÄ virtual-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ serviceentry-dev-get.yaml     # ServiceEntry para Cluster B
‚îÇ   ‚îî‚îÄ‚îÄ kustomization.yaml
‚îú‚îÄ‚îÄ gke-dev-get-app-engine/           # Manifestos do Cluster B
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml               # Aplica√ß√£o principal (netshoot com servidor HTTP + ferramentas)
‚îÇ   ‚îú‚îÄ‚îÄ service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml
‚îÇ   ‚îú‚îÄ‚îÄ gateway.yaml
‚îÇ   ‚îú‚îÄ‚îÄ virtual-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ serviceentry-dev-dis.yaml     # ServiceEntry para Cluster A
‚îÇ   ‚îî‚îÄ‚îÄ kustomization.yaml
‚îî‚îÄ‚îÄ arquivos-teste/                    # Arquivos de teste arquivados
    ‚îî‚îÄ‚îÄ test-pod.yaml
```

## üöÄ Deploy

### Aplicar Manifestos nos Clusters

```bash
# Cluster A (dev-dis-app-engine)
cd gke-dev-dis-app-engine
kubectl apply -k . --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine

# Cluster B (dev-get-app-engine)
cd ../gke-dev-get-app-engine
kubectl apply -k . --context=gke_prj-dev-get-app-gke-cple_southamerica-east1_gke-dev-get-app-engine
```

### Verificar Status dos Pods

```bash
# Cluster A
kubectl get pods -n dev-dis-test --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine

# Cluster B
kubectl get pods -n dev-get-test --context=gke_prj-dev-get-app-gke-cple_southamerica-east1_gke-dev-get-app-engine
```

**Resultado esperado**: Pods com status `Running` e `READY 2/2` (aplica√ß√£o + sidecar Istio)

**Nota**: Os pods usam a imagem `nicolaka/netshoot:latest` que possui tanto servidor HTTP quanto ferramentas de rede (`curl`, `nslookup`, etc.), eliminando a necessidade de pods de teste separados.

## üß™ Testes Manuais

### Pr√©-requisitos

- `kubectl` configurado com acesso a ambos os clusters
- Pods rodando em ambos os clusters

### Teste 1: Verificar DNS (Falha Esperada)

```bash
# Obter pod do Cluster A (tem servidor HTTP + ferramentas de rede)
POD_NAME=$(kubectl get pod -l app=dev-dis-test -n dev-dis-test \
  --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine \
  -o jsonpath='{.items[0].metadata.name}')

# Tentar resolver DNS do servi√ßo do Cluster B
kubectl exec -n dev-dis-test $POD_NAME \
  --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine \
  -- nslookup dev-get-test.dev-get-test.svc.cluster.local
```

**Resultado esperado**: `NXDOMAIN` - DNS n√£o resolve servi√ßos de outros clusters

### Teste 2: Testar Conectividade Direta por IP

```bash
# Obter IP do pod do Cluster B
POD_IP_B=$(kubectl get pod -l app=dev-get-test -n dev-get-test \
  --context=gke_prj-dev-get-app-gke-cple_southamerica-east1_gke-dev-get-app-engine \
  -o jsonpath='{.items[0].status.podIP}')

# Testar conectividade TCP direta
kubectl exec -n dev-dis-test $POD_NAME \
  --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine \
  -- curl -v http://${POD_IP_B}:5678/
```

**Resultado esperado**: Conex√£o TCP estabelecida, mas pode ser resetada pelo Istio (sem ServiceEntry)

### Teste 3: Verificar ServiceEntry

```bash
# Verificar ServiceEntry no Cluster A
kubectl get serviceentry -n dev-dis-test \
  --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine

# Verificar status do ServiceEntry
kubectl get serviceentry dev-get-test-cross-cluster -n dev-dis-test \
  --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine \
  -o yaml | grep -A 10 "status:"
```

**Resultado esperado**: ServiceEntry criado e aceito, mas DNS ainda n√£o resolve

### Teste 4: Verificar Sidecar do Istio

```bash
# Verificar containers no pod da aplica√ß√£o
APP_POD=$(kubectl get pod -l app=dev-dis-test -n dev-dis-test \
  --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine \
  -o jsonpath='{.items[0].metadata.name}')

kubectl get pod $APP_POD -n dev-dis-test \
  --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine \
  -o jsonpath='{.spec.containers[*].name}'
```

**Resultado esperado**: `dev-dis-test istio-proxy` - Sidecar injetado automaticamente

### Teste 5: Testar Comunica√ß√£o Cross-Cluster via ServiceEntry

```bash
# Testar comunica√ß√£o cross-cluster usando o pod principal
kubectl exec -n dev-dis-test $POD_NAME \
  --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine \
  -- curl -v http://dev-get-test.dev-get-test.svc.cluster.local:80/
```

**Resultado esperado**: Mesmo com ServiceEntry configurado, o DNS ainda n√£o resolve. Isso confirma que √© necess√°rio habilitar multi-cluster mesh para comunica√ß√£o autom√°tica.

## ‚ùå Erros Encontrados

### Erro 1: DNS n√£o resolve servi√ßos cross-cluster

**Comando executado:**
```bash
kubectl exec -n dev-dis-test mesh-test-client \
  --context=gke_prj-dev-dis-app-gke-cple_southamerica-east1_gke-dev-dis-app-engine \
  -- curl -v http://dev-get-test.dev-get-test.svc.cluster.local:80/server
```

**Erro:**
```
* Could not resolve host: dev-get-test.dev-get-test.svc.cluster.local
curl: (6) Could not resolve host
```

**Motivo:**
O DNS do Kubernetes n√£o resolve servi√ßos de outros clusters. O ServiceEntry do Istio informa como rotear o tr√°fego, mas n√£o cria um registro DNS. Para comunica√ß√£o cross-cluster funcionar automaticamente, √© necess√°rio que o **Istio Control Plane Multi-Cluster** esteja habilitado.

### Erro 2: ServiceEntry com MESH_INTERNAL n√£o suportado

**Erro:**
```
ERROR: MESH_INTERNAL is not supported
```

**Solu√ß√£o:**
Alterado para `location: MESH_EXTERNAL` no ServiceEntry.

### Erro 3: Container sem curl/nslookup (RESOLVIDO)

**Erro:**
```
exec: "curl": executable file not found in $PATH
exec: "nslookup": executable file not found in $PATH
```

**Motivo:**
As imagens `hashicorp/http-echo` s√£o muito minimalistas e n√£o possuem ferramentas como `curl` ou `nslookup`. 

**Solu√ß√£o:**
Substitu√≠da a imagem `hashicorp/http-echo` por `nicolaka/netshoot:latest` que possui:
- ‚úÖ Servidor HTTP (via Python)
- ‚úÖ Ferramentas de rede (`curl`, `nslookup`, `dig`, `nc`, etc.)
- ‚úÖ Todas as ferramentas necess√°rias para testes e troubleshooting

Isso elimina a necessidade de pods de teste separados, simplificando a arquitetura.

## üîç Motivos dos Problemas

### Por que o DNS n√£o resolve?

1. **DNS do Kubernetes √© local ao cluster**: Cada cluster tem seu pr√≥prio DNS (`kube-dns` ou `CoreDNS`) que s√≥ conhece servi√ßos dentro do pr√≥prio cluster.

2. **ServiceEntry n√£o cria DNS**: O ServiceEntry do Istio informa ao control plane como rotear tr√°fego, mas n√£o cria registros DNS. Ele funciona apenas para tr√°fego que j√° est√° sendo roteado pelo Istio.

3. **Multi-cluster Mesh necess√°rio**: Para comunica√ß√£o cross-cluster autom√°tica, o **Istio Control Plane Multi-Cluster** precisa estar habilitado, permitindo que o Istio fa√ßa descoberta autom√°tica de servi√ßos atrav√©s do control plane compartilhado.

### Documenta√ß√£o Oficial do GCP

Segundo a [documenta√ß√£o oficial do Anthos Service Mesh](https://cloud.google.com/service-mesh/docs/overview):

> **Multi-cluster Service Mesh**: Para comunica√ß√£o cross-cluster, voc√™ precisa habilitar o multi-cluster service mesh. Isso permite que o Istio Control Plane fa√ßa descoberta autom√°tica de servi√ßos em m√∫ltiplos clusters e roteie o tr√°fego entre eles.

**Refer√™ncias:**
- [Anthos Service Mesh - Multi-cluster](https://cloud.google.com/service-mesh/docs/multicluster-overview)
- [Configurar Multi-cluster Service Mesh](https://cloud.google.com/service-mesh/docs/multicluster-setup)
- [Istio Multi-cluster](https://istio.io/latest/docs/setup/install/multicluster/)

## ‚öñÔ∏è Benef√≠cios do ASM com Multi-cluster vs Sem Multi-cluster

### Com Multi-cluster Service Mesh Habilitado ‚úÖ

- ‚úÖ **Descoberta autom√°tica de servi√ßos**: Servi√ßos em qualquer cluster s√£o automaticamente descobertos
- ‚úÖ **DNS cross-cluster**: Resolu√ß√£o autom√°tica de FQDN entre clusters
- ‚úÖ **Load balancing autom√°tico**: Distribui√ß√£o de carga entre pods em m√∫ltiplos clusters
- ‚úÖ **Failover autom√°tico**: Se um cluster falhar, tr√°fego √© redirecionado automaticamente
- ‚úÖ **Observabilidade unificada**: M√©tricas, logs e traces de todos os clusters em um √∫nico lugar
- ‚úÖ **Gerenciamento centralizado**: Pol√≠ticas de seguran√ßa e roteamento aplicadas globalmente
- ‚úÖ **Sem ServiceEntry manual**: N√£o √© necess√°rio criar ServiceEntry para cada servi√ßo cross-cluster
- ‚úÖ **Service Mesh completo**: Todas as funcionalidades do Istio funcionam entre clusters

### Sem Multi-cluster Service Mesh (Cen√°rio Atual) ‚ö†Ô∏è

- ‚ö†Ô∏è **ServiceEntry manual necess√°rio**: Precisa criar ServiceEntry com IPs est√°ticos para cada servi√ßo
- ‚ö†Ô∏è **DNS n√£o funciona**: N√£o √© poss√≠vel resolver servi√ßos de outros clusters via DNS
- ‚ö†Ô∏è **Sem descoberta autom√°tica**: Mudan√ßas em servi√ßos requerem atualiza√ß√£o manual do ServiceEntry
- ‚ö†Ô∏è **Sem load balancing cross-cluster**: Load balancing funciona apenas dentro do cluster
- ‚ö†Ô∏è **Sem failover autom√°tico**: Falhas em um cluster n√£o s√£o tratadas automaticamente
- ‚ö†Ô∏è **Observabilidade fragmentada**: M√©tricas e logs separados por cluster
- ‚ö†Ô∏è **Manuten√ß√£o manual**: IPs de pods mudam, requerendo atualiza√ß√£o constante dos ServiceEntries
- ‚úÖ **Funcionalidades dentro do cluster**: Todas as funcionalidades do Istio funcionam normalmente dentro de cada cluster

## üìä Compara√ß√£o de Cen√°rios

| Funcionalidade | Sem Multi-cluster | Com Multi-cluster |
|----------------|-------------------|-------------------|
| DNS Cross-cluster | ‚ùå N√£o funciona | ‚úÖ Funciona automaticamente |
| Descoberta de Servi√ßos | ‚ùå Manual (ServiceEntry) | ‚úÖ Autom√°tica |
| Load Balancing | ‚ö†Ô∏è Apenas intra-cluster | ‚úÖ Cross-cluster |
| Failover | ‚ùå Manual | ‚úÖ Autom√°tico |
| Observabilidade | ‚ö†Ô∏è Fragmentada | ‚úÖ Unificada |
| Manuten√ß√£o | ‚ö†Ô∏è Alta (IPs est√°ticos) | ‚úÖ Baixa (autom√°tica) |
| ServiceEntry | ‚ö†Ô∏è Necess√°rio | ‚úÖ N√£o necess√°rio |
| Seguran√ßa | ‚úÖ Por cluster | ‚úÖ Global |

## üîß Como Habilitar Multi-cluster Service Mesh

### Pr√©-requisitos

1. Clusters no mesmo Fleet do GCP
2. VPC compartilhada ou VPC conectadas
3. ASM habilitado em ambos os clusters
4. Permiss√µes adequadas no GCP

### Comandos

```bash
# Verificar se os clusters est√£o no mesmo fleet
gcloud container fleet memberships list

# Verificar configura√ß√£o atual do ASM
gcloud container fleet mesh describe

# Habilitar multi-cluster mesh (exemplo)
gcloud container fleet mesh update \
  --management automatic \
  --memberships CLUSTER_A,CLUSTER_B

# Verificar status
gcloud container fleet mesh describe --format="yaml(multicluster)"
```

**Documenta√ß√£o completa**: [Configurar Multi-cluster Service Mesh](https://cloud.google.com/service-mesh/docs/multicluster-setup)

## üìù Notas Importantes

1. **ServiceEntry com IP est√°tico**: No cen√°rio atual, os ServiceEntries usam IPs est√°ticos dos pods. Esses IPs mudam quando pods s√£o recriados, exigindo atualiza√ß√£o manual.

2. **Namespace labels**: Ambos os namespaces t√™m o label `istio.io/rev: asm-managed` para inje√ß√£o autom√°tica do sidecar.

3. **Portas**: 
   - Cluster A: Container escuta na porta 80
   - Cluster B: Container escuta na porta 5678, Service exp√µe na porta 80

4. **Test-pod.yaml**: Foi arquivado em `arquivos-teste/` pois n√£o √© mais necess√°rio - os pods principais j√° possuem todas as ferramentas de teste.

5. **Imagens utilizadas**:
   - **Aplica√ß√µes principais**: `nicolaka/netshoot:latest` 
     - Servidor HTTP simples (via Python)
     - Ferramentas de rede completas (`curl`, `nslookup`, `dig`, `nc`, `tcpdump`, etc.)
     - Elimina necessidade de pods de teste separados

## üîó Refer√™ncias

- [Anthos Service Mesh - Documenta√ß√£o Oficial](https://cloud.google.com/service-mesh/docs)
- [Multi-cluster Service Mesh Overview](https://cloud.google.com/service-mesh/docs/multicluster-overview)
- [Istio Multi-cluster Setup](https://istio.io/latest/docs/setup/install/multicluster/)
- [ServiceEntry Documentation](https://istio.io/latest/docs/reference/config/networking/service-entry/)

## üë• Autores

Teste realizado para validar comunica√ß√£o cross-cluster no Cloud Service Mesh do GCP.

---

**√öltima atualiza√ß√£o**: 2025-11-18
